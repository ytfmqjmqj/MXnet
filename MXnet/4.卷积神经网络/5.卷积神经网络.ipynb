{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.LeNet模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gluonbook as gb\n",
    "import mxnet as mx\n",
    "from mxnet import autograd, gluon, init, nd\n",
    "from mxnet.gluon import loss as gloss, nn\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential()\n",
    "net.add(nn.Conv2D(channels = 6, kernel_size = 5, activation = 'sigmoid'),\n",
    "       nn.MaxPool2D(pool_size = 2, strides = 2),\n",
    "       nn.Conv2D(channels = 16, kernel_size = 5, activation  = 'sigmoid'),\n",
    "       nn.MaxPool2D(pool_size = 2, strides = 2),\n",
    "       # Dense会默认将（批量大小，通道，高，宽）形状的输入转换成\n",
    "       # （批量大小， 通道 ＊ 高 ＊ 宽）形状的输入)\n",
    "        nn.Dense(120, activation = 'sigmoid'),\n",
    "        nn.Dense(84, activation = 'sigmoid'),\n",
    "        nn.Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv0 output shape:\t (1, 6, 24, 24)\n",
      "pool0 output shape:\t (1, 6, 12, 12)\n",
      "conv1 output shape:\t (1, 16, 8, 8)\n",
      "pool1 output shape:\t (1, 16, 4, 4)\n",
      "dense0 output shape:\t (1, 120)\n",
      "dense1 output shape:\t (1, 84)\n",
      "dense2 output shape:\t (1, 10)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "构造一个高和宽均为28的单通道数据样本，并逐层进行前向计算来查看每个层的输出形状\n",
    "'''\n",
    "X = nd.random.uniform(shape = (1, 1, 28, 28))\n",
    "net.initialize()\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.name, 'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.获取数据和训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_iter, test_iter = gb.load_data_fashion_mnist(batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cpu(0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "尝试在gpu(0)上创建NDArray，如果成功则使用gpu(0)，否则仍然使用CPU\n",
    "'''\n",
    "def try_gpu4():\n",
    "    try:\n",
    "        ctx = mx.gpu()\n",
    "        _ = nd.zeros((1, ), ctx = ctx)\n",
    "    except mx.base.MXNetError:\n",
    "        ctx = mx.cpu()\n",
    "    return ctx\n",
    "\n",
    "ctx = try_gpu4()\n",
    "ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "gluonbook模块没有accuracy属性，自己来定义\n",
    "'''\n",
    "def accuracy(y_hat, y):\n",
    "    return (y_hat.argmax(axis = 1) == y.astype('float32')).mean().asscalar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "as_in_context函数将数据复制到GPU上，例如gpu(0)\n",
    "'''\n",
    "def evaluate_accuracy(data_iter, net, ctx):\n",
    "    acc = nd.array([0], ctx = ctx)\n",
    "    for X, y in data_iter:\n",
    "        # 如果ctx是GPU，将数据复制到GPU上\n",
    "        X, y = X.as_in_context(ctx), y.as_in_context(ctx)\n",
    "        acc += accuracy(net(X), y)\n",
    "    return acc.asscalar() / len(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ch5(net, train_iter, test_iter, batch_size, trainer, ctx, num_epochs):\n",
    "    print('training on', ctx)\n",
    "    loss = gloss.SoftmaxCrossEntropyLoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, start = 0, 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            X, y = X.as_in_context(ctx), y.as_in_context(ctx)\n",
    "            with autograd.record():\n",
    "                y_hat = net(X)\n",
    "                l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            trainer.step(batch_size)\n",
    "            train_l_sum += l.mean().asscalar()\n",
    "            train_acc_sum += accuracy(y_hat, y)\n",
    "        test_acc = evaluate_accuracy(test_iter, net, ctx)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\n",
    "             'time %.1f sec' % (epoch + 1, train_l_sum / len(train_iter),\n",
    "                               train_acc_sum / len(train_iter),\n",
    "                               test_acc, time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cpu(0)\n",
      "epoch 1, loss 2.3194, train acc 0.101, test acc 0.099, time 13.1 sec\n",
      "epoch 2, loss 2.2690, train acc 0.127, test acc 0.417, time 13.3 sec\n",
      "epoch 3, loss 1.1754, train acc 0.529, test acc 0.670, time 12.5 sec\n",
      "epoch 4, loss 0.7969, train acc 0.688, test acc 0.733, time 12.5 sec\n",
      "epoch 5, loss 0.6778, train acc 0.733, test acc 0.751, time 12.6 sec\n",
      "epoch 6, loss 0.6149, train acc 0.759, test acc 0.788, time 12.7 sec\n",
      "epoch 7, loss 0.5648, train acc 0.777, test acc 0.793, time 12.6 sec\n",
      "epoch 8, loss 0.5285, train acc 0.794, test acc 0.815, time 12.9 sec\n",
      "epoch 9, loss 0.4929, train acc 0.808, test acc 0.806, time 12.8 sec\n",
      "epoch 10, loss 0.4652, train acc 0.822, test acc 0.834, time 13.0 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.9, 10\n",
    "net.initialize(force_reinit = True, ctx = ctx, init = init.Xavier())\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr})\n",
    "train_ch5(net, train_iter, test_iter, batch_size, trainer, ctx, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
